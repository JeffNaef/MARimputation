#methods <- c("DRF", "cart", "missForest")
#methods <- c("DRF", "cart")
methods <- c( "DRF", "cart","norm.predict", "missForest", "norm.nob")
m<-1
# data sets we use in the paper
# real data sets: dataset = ...
# "airfoil","Boston","concrete.compression","connectionist.bench.vowel",
# "yacht","climate.model.crashes", "CASchools", "ecoli","wine","yeast", "ionosphere"
# "iris","concrete.slump","seeds","planning.relax",
set.seed(2) #1
seeds <- sample(c(0:2000),100,replace = FALSE)
######################################################################################################
########################################### mask, imputation and evaluation ##########################
######################################################################################################
Results<-list()
#Resample data
X <- genData_real(dataset = "real_spam", n = n)
X <- as.matrix(X)
colnames(X)<-NULL
d <- ncol(X)
n.train <- nrow(X)
colnames(X) <- paste0("X",1:ncol(X))
#X.NA <- genMask(X, mech = missing.mech, pmiss=pmiss)
##Focus on this!
#patterns<-ampute.default.patterns(d )[1:5,]
#patterns[1,d-2]<-0
#patterns[2,d-1]<-0
#patterns[3,d]<-0
M<-apply(X,2, function(x) sample(c(0,1), size=length(x), replace=T, prob = c(1-0.2,0.2) )  )
X.NA<-X
X.NA[M==1] <- NA
X <- X[rowSums(is.na(X.NA)) < d,]
X.NA <- X.NA[rowSums(is.na(X.NA)) < d,]
################################## imputations #########################################
########################################################################################
## Add drf
imputations <- doimputation(X.NA=X.NA, methods=methods, m=m) # , blocksize=2
methods<-imputations$methods
imputations <-imputations$imputations
# append the truth, that is X
# for ( i in 1:m){
#
#   if (data.type == "simulated"){
#     imputations[["truth"]][[i]] <- as.data.frame(X)
#   }else{ imputations[["truth"]][[i]] <- as.data.frame(X)}
#
#   names(imputations[["truth"]])[[i]] <- paste0(i)
# }
#
# methods <- c(methods, "truth")
# names(imputations) <- methods
imputationfuncs<-list()
for (method in methods){
##Probably not the smartes solution
imputationfuncs[[method]][[1]] <- method
imputationfuncs[[method]][[2]] <- function(X,m, method){
doimputation(X.NA=X, methods=method, m=m,print=F, visitSequence="arabic", maxit = 1)}
}
################################## evaluations #########################################
########################################################################################
# #Step 1: Without access to true underlying data, check Iscore
# start_time <- Sys.time()
# new.score.list.drf <- Iscores_new(X.NA,imputations,score="drf2", imputationfuncs=imputationfuncs, projections=T, projectionsize=10)
# end_time <- Sys.time()
#
# end_time-start_time
start_time <- Sys.time()
new.score.list.imp <- Iscores_new(X.NA,imputations,score="mulitpleimp2", imputationfuncs=imputationfuncs, projections=T, projectionsize=5, maxlength = 10)
end_time <- Sys.time()
end_time-start_time
#new.score.drf <- unlist(lapply(new.score.list.drf, function(x) x$score))
new.score.imp <- unlist(lapply(new.score.list.imp, function(x) x$score))
#Step 2: With access to the full data, check energy score:
# So far only for m=1!!!
escore<-rep(0, length(methods))
names(escore)<-methods
for (method in methods){
for (j in 1:m){
Ximp<-imputations[[method]][[j]]
colnames(Ximp)<-paste0("X",1:ncol(X))
escore[method]<-escore[method]+eqdist.e( rbind(X,Ximp), c(nrow(X), nrow(Ximp))  )
}
escore[method] <- -1/m*escore[method]
}
#  print( sort( round( unlist(new.score.drf)/sum(unlist(new.score.drf)),3) , decreasing=T)   )
#  print( sort( round( unlist(new.score.imp)/sum(unlist(new.score.imp)),3) , decreasing=T)   )
#  print( sort( round(escore/sum(escore),3) , decreasing=T)   )
print("m-score2:")
print( sort( round( unlist(new.score.imp)/sum(unlist(new.score.imp)),3) , decreasing=T)   )
print("e-score")
print( sort( round(escore/sum(escore),3) , decreasing=T)   )
Results <- list(new.score.imp = new.score.imp,new.score.drf=new.score.drf , energy.score=escore)
new.score.imp
escore
print( sort( round( unlist(new.score.imp)/sum(unlist(new.score.imp)),3) , decreasing=T)   )
print( sort( round(escore/sum(escore),3) , decreasing=T)   )
filename = "Application_3"
assign(filename, Results)
save(Results, file=paste(filename, ".Rda",sep=""))
end_time-start_time
new.score.list.imp
### Application Ready to Run #####
##Need a different dataset here.
# Potential datets:
#yeast
#######################################
###One real dataset with ampute MAR ###
#######################################
###Need to find a solution for binary variables!!!
require(energy)
require(mice)
print("mice loaded")
require(data.table)
print("data.table loaded")
require(ranger)
print("ranger loaded")
require(parallel)
print("parallel loaded")
require(missMDA)
print("missMDA loaded")
library(tidyverse)
print("tidyverse loaded")
library(softImpute)
print("softImpute loaded")
library(Matrix)
print("Matrix loaded")
library(readxl)
print("readxl loaded")
library(plotrix)
print("plotrix loaded")
library(missForest)
print("missForest loaded")
#library(naniar)
#print("naniar loaded")
require(kernlab)
print("kernlab loaded")
library(MASS)
print("MASS loaded")
library(AER)
print("AER loaded")
library(missForest)
print("missForest loaded")
library(Iscores)
print("IScores loaded")
source("helpers.R")
#source("Iscores_new.R")
##Add drf!!
#methods <- c("DRF", "cart", "missForest")
methods <- c("DRF","cart","norm.predict", "missForest", "norm.nob", "pmm")
#methods <- c("cart","norm.predict", "missForest", "norm.nob", "pmm")
#methods <- c("pmm", "midastouch","mipca", "cart", "sample", "norm.predict",
#             "mean","rf", "missForest")
missing.mech <- "MAR"
pmiss <- 0.6
nrep.total<-10
## Maybe use spam??
#dataset <- "multivariateGaussian"
#data.type <- "simulated"
dataset <- "real_airquality"
#dataset <- "yeast"
#dataset <- "real_birthdata"
data.type <- "real"
## TO DO
## 1.Create Nice multivariate Gaussian dataset with 3-4 patterns with changing distribution!! (say 5 fully observed values and
## that change their distribution in each pattern + always the same conditional distribution)
## => Show how hard imputation can be + score proper + energy distance useful
## 2. Use real dataset with ampute MAR
## => Show score proper + energy distance useful
## 3. Use spam dataset and impute with DRF block + GAIN
# data sets we use in the paper
# real data sets: dataset = ...
# "airfoil","Boston","concrete.compression","connectionist.bench.vowel",
# "yacht","climate.model.crashes", "CASchools", "ecoli","wine","yeast", "ionosphere"
# "iris","concrete.slump","seeds","planning.relax",
parallelize <- TRUE
num.trees.per.proj <- 5 # need to be at least 2
min.node.size <- 10
m <- 1
n<-2000
real.data <- TRUE
n.cores <- 10
frac.subsample<-0.9
set.seed(2) #1
seeds <- sample(c(0:2000),100,replace = FALSE)
######################################################################################################
########################################### mask, imputation and evaluation ##########################
######################################################################################################
Results<-list()
#length(ids.jack)
#Results <- lapply(1:10, function(s){
for (s in 1:10){
set.seed(seeds[s])
#Resample data
X <- genData_real(dataset = dataset, n = n)
X <- as.matrix(X)
colnames(X)<-NULL
d <- ncol(X)
n.train <- nrow(X)
#X.NA <- genMask(X, mech = missing.mech, pmiss=pmiss)
##Focus on this!
#patterns<-ampute.default.patterns(d )[1:5,]
patterns<-matrix(1, nrow=4, ncol=d)
patterns[1,1]<-0
patterns[2,2]<-0
patterns[3,3]<-0
patterns[4,4]<-0
#patterns[1,d-2]<-0
#patterns[2,d-1]<-0
#patterns[3,d]<-0
X.NA<-ampute(X,
prop = pmiss,
patterns = patterns,
freq = NULL,
mech = missing.mech)$amp
# Throw away observations which are only NA
X <- X[rowSums(is.na(X.NA)) < d,]
X.NA <- X.NA[rowSums(is.na(X.NA)) < d,]
colnames(X)<-NULL
################################## imputations #########################################
########################################################################################
## Add drf
imputations <- doimputation(X.NA=X.NA, methods=methods, m=m)
methods<-imputations$methods
imputations <-imputations$imputations
# append the truth, that is X
# for ( i in 1:m){
#
#   if (data.type == "simulated"){
#     imputations[["truth"]][[i]] <- as.data.frame(X)
#   }else{ imputations[["truth"]][[i]] <- as.data.frame(X)}
#
#   names(imputations[["truth"]])[[i]] <- paste0(i)
# }
#
# methods <- c(methods, "truth")
# names(imputations) <- methods
imputationfuncs<-list()
for (method in methods){
##Probably not the smartes solution
imputationfuncs[[method]][[1]] <- method
imputationfuncs[[method]][[2]] <- function(X,m, method){
doimputation(X.NA=X, methods=method, m=m,print=FALSE, visitSequence="arabic", maxit = 1)}
}
################################## evaluations #########################################
########################################################################################
#Step 1: Without access to true underlying data, check Iscore
start_time <- Sys.time()
new.score.list.drf <- Iscores_new(X.NA,imputations,score="drf2", imputationfuncs=imputationfuncs)
end_time <- Sys.time()
end_time-start_time
start_time <- Sys.time()
new.score.list.imp <- Iscores_new(X.NA,imputations,score="mulitpleimp2", imputationfuncs=imputationfuncs)
end_time <- Sys.time()
end_time-start_time
new.score.drf <- unlist(lapply(new.score.list.drf, function(x) x$score))
new.score.imp <- unlist(lapply(new.score.list.imp, function(x) x$score))
#Step 2: With access to the full data, check energy score:
# So far only for m=1!!!
escore<-rep(0, length(methods))
names(escore)<-methods
for (method in methods){
for (j in 1:m){
Ximp<-imputations[[method]][[j]]
escore[method]<-escore[method]+eqdist.e( rbind(X,Ximp), c(nrow(X), nrow(Ximp))  )
}
escore[method] <- -1/m*escore[method]
}
#  print( sort( round( unlist(new.score.drf)/sum(unlist(new.score.drf)),3) , decreasing=T)   )
#  print( sort( round( unlist(new.score.imp)/sum(unlist(new.score.imp)),3) , decreasing=T)   )
#  print( sort( round(escore/sum(escore),3) , decreasing=T)   )
print("drf-score2:")
print( sort( round( unlist(new.score.drf)/sum(unlist(new.score.drf)),3) , decreasing=T)   )
print("m-score2:")
print( sort( round( unlist(new.score.imp)/sum(unlist(new.score.imp)),3) , decreasing=T)   )
print("e-score")
print( sort( round(escore/sum(escore),3) , decreasing=T)   )
print(paste0("nrep ",s, " out of ", nrep.total ))
print(paste0("nrep ",s, " out of ", nrep.total ))
Results[[s]] <- list(new.score.imp = new.score.imp,new.score.drf=new.score.drf , energy.score=escore)
#return(list(new.score.imp = new.score.imp,new.score.drf=new.score.drf , energy.score=escore))
}
imputations
imputations$DRF
imputationfuncs<-list()
for (method in methods){
##Probably not the smartes solution
imputationfuncs[[method]][[1]] <- method
imputationfuncs[[method]][[2]] <- function(X,m, method){
doimputation(X.NA=X, methods=method, m=m,print=FALSE, visitSequence="arabic", maxit = 1)}
}
start_time <- Sys.time()
new.score.list.drf <- Iscores_new(X.NA,imputations,score="drf2", imputationfuncs=imputationfuncs)
end_time <- Sys.time()
new.score.list.drf
start_time <- Sys.time()
new.score.list.imp <- Iscores_new(X.NA,imputations,score="mulitpleimp2", imputationfuncs=imputationfuncs)
methods
imputationfuncs
start_time <- Sys.time()
new.score.list.imp <- Iscores_new(X.NA,imputations,score="mulitpleimp2", imputationfuncs=imputationfuncs)
debug(Iscores_new)
new.score.list.imp <- Iscores_new(X.NA,imputations,score="mulitpleimp2", imputationfuncs=imputationfuncs)
debug(Iscores_new_perimp)
method<-"norm.predict"
Imputationlist
imputationfunc
HXmj
imputationfunc[[2]](X=X[,!(colnames(Ximp1) %in% j) & (colnames(Ximp1) %in% A), drop=F]  , m=1, method= imputationfunc[[1]])$imputations[[1]][[1]]
Xartificial
m
imputationfunc
debug(doimputation)
imputationfunc[[2]](X=X[,!(colnames(Ximp1) %in% j) & (colnames(Ximp1) %in% A), drop=F]  , m=1, method= imputationfunc[[1]])$imputations[[1]][[1]]
mice(X.NA, method = method, m = m)
m
imputationfunc[[2]](X=Xartificial  , m=m, method= imputationfunc[[1]])
m
mice(X.NA, method = method, m = m)
warning()
blub <- mice(X.NA, method = method, m = m, ...)
blub
d <- 10  # number of dimensions
m <- 50  # number of samples from multivariate forecast distribution
# parameters for multivariate normal example
mu0 <- rep(0, d)
mu <- rep(1, d)
S0 <- S <- diag(d)
S0[S0==0] <- 0.2
S[S==0] <- 0.1
# generate samples from multivariate normal distributions
obs <- drop(mu0 + rnorm(d) %*% chol(S0))
fc_sample <- replicate(m, drop(mu + rnorm(d) %*% chol(S)))
# compute Energy Score
es_sample(y = obs, dat = fc_sample)
(firstpart<-mean( sapply(1:m, function(j)  norm(fc_sample[,j, drop=F]- obs,type="F")    )  ))
scoringRules:::esC_xy(obs, fc_sample, rep(1/m,m))
D<-matrix(NaN, nrow=m, ncol=m)
for (i in 1:m){
for (j in 1:m){
D[i,j]<- norm(fc_sample[,j, drop=F] - fc_sample[,i, drop=F], type="F")
}
}
w<-rep(1/m,m)
secondpart<-w%*%D%*%w
secondpart
scoringRules:::esC_xx(fc_sample, rep(1/m,m))
library(kernlab)
?kernlab
fc_sample
D0<-D
library(kernlab)
D <- sqrt(diag(kernelMatrix(t(fc_sample), kernel = "vanilladot") - 2 * t(fc_sample) %*% fc_sample + diag(t(fc_sample) %*% fc_sample)))
D <- outer(rowMeans(fc_sample^2), rowMeans(fc_sample^2), FUN = function(x, y) sqrt(sum(x - y)))
rowMeans(fc_sample^2)
D <- outer(rowMeans(fc_sample^2), rowMeans(fc_sample^2), FUN = function(x, y) sqrt(sum(x - y)))
kernelMatrix(t(fc_sample), kernel = "vanilladot")
t(fc_sample)
?kernelMatrix
kernelMatrix(t(fc_sample), kernel = "vanilladot")
kernelMatrix(t(fc_sample), kernel = vanilladot)
kernelMatrix(t(fc_sample), kernel = vanilladot() )
D <- sqrt(diag(kernelMatrix(t(fc_sample),  kernel = vanilladot()) - 2 * t(fc_sample) %*% fc_sample + diag(t(fc_sample) %*% fc_sample)))
D
kernelMatrix(y=fc_sample,x=t(fc_sample),  kernel = vanilladot())
kernelMatrix(y=fc_sample,x=fc_sample,  kernel = vanilladot())
D
m
D<-matrix(NaN, nrow=m, ncol=m)
for (i in 1:m){
for (j in 1:m){
D[i,j]<- norm(fc_sample[,j, drop=F] - fc_sample[,i, drop=F], type="F")
}
}
dim(D)
kernelMatrix(y=t(fc_sample),x=t(fc_sample),  kernel = vanilladot())
D1<-kernelMatrix(y=t(fc_sample),x=t(fc_sample),  kernel = vanilladot())
D
D[1,]
D1[1,]
outer(fc_sample, t(fc_sample), `-`)
D<-matrix(NaN, nrow=m, ncol=m)
for (i in 1:m){
for (j in 1:m){
# D[i,j]<- norm(fc_sample[,j, drop=F] - fc_sample[,i, drop=F], type="F")
D[i,j]<- fc_sample[,j, drop=F] - fc_sample[,i, drop=F]
}
}
outer(fc_sample, t(fc_sample), `-`)
new.score.list.imp <- Iscores_new(X.NA,imputations,score="mulitpleimp2", imputationfuncs=imputationfuncs)
new.score.list.imp <- Iscores_new(X.NA,imputations,score="mulitpleimp2", imputationfuncs=imputationfuncs)
method<-"norm.predict"
reticulate::repl_python()
from __future__ import absolute_import
- miss_rate: probability of missing components
print("hello")
# coding=utf-8
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
'''Main function for UCI letter and spam datasets.
'''
# Necessary packages
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
import argparse
import numpy as np
from data_loader import data_loader
from gain import gain
from utils import rmse_loss
def main (args):
'''Main function for UCI letter and spam datasets.
Args:
- data_name: letter or spam
- miss_rate: probability of missing components
- batch:size: batch size
- hint_rate: hint rate
- alpha: hyperparameter
- iterations: iterations
Returns:
- imputed_data_x: imputed data
- rmse: Root Mean Squared Error
'''
print("hello")
data_name = args.data_name
miss_rate = args.miss_rate
gain_parameters = {'batch_size': args.batch_size,
'hint_rate': args.hint_rate,
'alpha': args.alpha,
'iterations': args.iterations}
# Load data and introduce missingness
ori_data_x, miss_data_x, data_m = data_loader(data_name, miss_rate)
# Impute missing data
imputed_data_x = gain(miss_data_x, gain_parameters)
# Report the RMSE performance
rmse = rmse_loss (ori_data_x, imputed_data_x, data_m)
print()
print('RMSE Performance: ' + str(np.round(rmse, 4)))
return imputed_data_x, rmse
if __name__ == '__main__':
# Inputs for the main function
parser = argparse.ArgumentParser()
parser.add_argument(
'--data_name',
choices=['letter','spam'],
default='spam',
type=str)
parser.add_argument(
'--miss_rate',
help='missing data probability',
default=0.2,
type=float)
parser.add_argument(
'--batch_size',
help='the number of samples in mini-batch',
default=128,
type=int)
parser.add_argument(
'--hint_rate',
help='hint probability',
default=0.9,
type=float)
parser.add_argument(
'--alpha',
help='hyperparameter',
default=100,
type=float)
parser.add_argument(
'--iterations',
help='number of training interations',
default=10000,
type=int)
args = parser.parse_args()
# Calls main function
imputed_data, rmse = main(args)
# Example usage:
library(reticulate)
install.packages("reticulate")
# Example usage:
library(reticulate)
n <- 2000
d <- 3
X <- matrix(rnorm(n * d, mean = 0, sd = 2), ncol = d, nrow = n)
# M: Pattern matrix
M <- apply(X, 2, function(x) sample(c(0, 1), size = length(x), replace = TRUE, prob = c(1 - 0.2, 0.2)))
X_NA[M == 1] <- NA
# X.NA: Matrix with missing values
X_NA<-X
X_NA[M == 1] <- NA
# GAIN parameters
gain_parameters <- list(
batch_size = 64L,
hint_rate = 0.9,
alpha = 10,
iterations = 10000L
)
# Impute missing values using GAIN
X_imputed <- gain(X_NA, gain_parameters)
setwd("C:/Users/jeffr/OneDrive/Today/MAR_project/Code/GAIN-master")
# Impute missing values using GAIN
X_imputed <- gain(X_NA, gain_parameters)
reticulate::source_python('C:/Users/jeffr/OneDrive/Today/MAR_project/Code/GAIN-master/gain.py')
reticulate::source_python('C:/Users/jeffr/OneDrive/Today/MAR_project/Code/GAIN-master/gain.py')
